  
import urllib
import json
import os
from flask import Flask
from flask import request
from flask import make_response
from flask import jsonify

import psycopg2
import urllib.parse
### Hatem dealing with google places api ########################
from googleplaces import GooglePlaces, types, lang

####### for google maps api######
import googlemaps
from datetime import datetime
from googlemaps import convert
from googlemaps.convert import as_list
import requests

#### for goto city Function libs
import jsonpickle
import simplejson as json

from urllib.request import urlopen
from bs4 import BeautifulSoup
import re
import sys
import wget
##############################
import csv


####



# Project
YOUR_API_KEY = 'AIzaSyCPFtscQTpvKikFNUfZGOWeZFLe2jt39HE'

# Other------
# YOUR_API_KEY = 'AIzaSyC1dyD2kzPmZPmM4-oGYnIH_0x--0hVSY8'
# 'AIzaSyAwd0OLvubYtKkEWwMe4Fe0DQpauX0pzlk'


robot_photo_url = ""

google_places = GooglePlaces(YOUR_API_KEY)
gmaps = googlemaps.Client(key=YOUR_API_KEY)



def get_attraction(city, user_lat_lng, text_for_search): 
#optional, one of them is used and the other should be empty #city is the key
# text_for_Search = attraction + " in " + city + " to have " + the_type + " around " + sp_area
# text_for_search = "food in tokyo to have pizza around akhibara"
# text_for_search = "restaurants in tokyo to have pizza around akhibara"
        if city != "":
                print("--> I got city, so I use google api with city")
                query_result = google_places.text_search(query=text_for_search, location=city, radius=20000)  # , types=[types.TYPE_FOOD])
        else:
                print("--> I didn't get city, so I use google api with user_lat_lng")
                query_result = google_places.text_search(query=text_for_search, location=user_lat_lng, radius=20000)  # , types=[types.TYPE_FOOD])

        # saving the array of places results to send as context later

        citydata = ''
        place_and_url = ""
        print("--> length of the Result Places Array: ", len(query_result.places)) #10.3.19
        #values = values[:-2] #10.3.19
        '''
        if len(query_result.places) >10:
                #a = a[0:10]
                query_result_places = query_result.places[0:5] #generated by hatem
        else:
                query_result_places = query_result.places #generated by hatem #pass
        print("--> length of the Result Places Array After Reduction: ", len(query_result_places)) #10.3.19
        '''

        #for query_result.has_next_page_token:
            #query_result_next_page = google_places.nearby_search(pagetoken=query_result.next_page_token)

        
        query_result_places = query_result.places
        pages_number = 1
        max_pages = 20 #5

        ## Lists
        place_name_list          = []
        place_geo_loc_list       = []
        place_id_list            = []
        place_url_list           = []
        plat_plng_list           = []
        place_photo_url_list     = []
        ##

        for pages_number in range(1, max_pages):
            print("---> Page number: ", pages_number)
            for place in query_result_places: #query_result.places: #generated by hatem
                # Returned places from a query are place summaries.
                # ok####-->#Mar2019#print_OFF#print(place.__dict__.keys())
                # #-->#Mar2019#print_OFF#print(place.__dict__)
                place_name    = place.name
                place_geo_loc = place.geo_location
                place_id      = place.place_id
                # hatem trouble shoot april 2
                # {'lat': Decimal('35.682717'), 'lng': Decimal('139.6870378')}
                place_id      = place.place_id
                place.get_details()
                place_url     = place.url
                # global place_and_url
            
                # lat = place_geo_loc['results'][0]['formatted_address']
                plat = str(place_geo_loc['lat'])
                plng = str(place_geo_loc['lng'])
            
                prating = "Rating: " + str(place.rating) + "/5"
                # '41.8337329,-87.7321554'
                # 'lat,lng'
                place_rating = str(place.rating) + "/5"

                plat_plng = plat + "," + plng

                #photoUrl = place.photos[0].getUrl({maxWidth: 400, maxHeight: 400})
                try:
                
                    photo = place.photos[0]
                    photo.get(maxheight=500, maxwidth=500)
                    #photo.mimetype
                    place_photo_url= photo.url
                    ##########-->#Mar2019#print_OFF#print("--->>> 2019 photo: ", place_photo_url)
                    ##-->#Mar2019#print_OFF#print("--->>> 2019 place_ID", place_id)
                    ##-->#Mar2019#print_OFF#print("--->>> 2019 place_URL", place_url)
                    #######################################
                except: #case that google did not provide photos for the place
                    #place_photo_url = "https://hanna-travel.com/wp-content/themes/blog-way/lp_assets/hanna_logo_white.png"
                     place_photo_url = "https://hanna-travel.com/hanna.png"
                '''
                place_and_url += "\n" + place_name + "\n" + \
                    "check it here:\n" + place_url + "\n"
                citydata += place_name + "\n" + place_url + \
                    "\n" + plat_plng + "\n" + prating + "\n" + place_photo_url + "#"
                #-->Feb2019 photos_added
                '''

                ## lists append
                place_name_list.append(place_name)
                place_geo_loc_list.append(place_geo_loc)
                place_id_list.append(place_id)
                place_url_list.append(place_url)
                plat_plng_list.append(plat_plng)
                place_photo_url_list.append(place_photo_url)

                ##

            #
                #------->photos Feb19 -->working but takes time
          
            if query_result.has_next_page_token:
               query_result_next_page = google_places.nearby_search(pagetoken=query_result.next_page_token)

               print("There is next page")
               query_result_places = query_result_next_page.places
               pages_number = pages_number + 1

            else:
               print("There is no next page, stopped at page number: ", pages_number)
               break



            #######################################
            

        # added "try except" on 14-11-2018 ####################################
        try:
                    citydata_array       = citydata.split("#")
                    that_place_info      = citydata_array[conindex]
                    that_place           = that_place_info.split("\n")
                    that_place_text      = that_place[0]
                    that_place_url       = that_place[1]
                    that_place_plat_plng = that_place[2]
                    that_place_prating   = that_place[3]
                    that_place_photo_url = that_place[4] #feb2019 photo
        except:
                    citydata_array       = ""
        #######################################################################
        #november

        ###print("citydata is: \n", citydata)

       # # Are there any additional pages of results?
        #if query_result.has_next_page_token:
            #query_result_next_page = google_places.nearby_search(pagetoken=query_result.next_page_token)
            
            #print("There is next page")
        return place_name_list, place_geo_loc_list, place_id_list, place_url_list, plat_plng_list, place_photo_url_list


def get_read_write_2(somedict):
   
   '''
   fs = wget.download(url="https://hanna-travel.com/goto_food_db_g.json")

   with open(fs, "r") as in_f:
       cate_lists_dict = jsonpickle.decode(json.load(in_f))
   '''

   somedict = cate_lists_dict #{"test": 1, "testing": 2}

   with open('mycsvfile.csv','wb') as f:
       w = csv.writer(sys.stderr) #csv.writer(f)
       w.writerow(somedict.keys())
       w.writerow(somedict.values())

#-----main

city = "Tokyo"
user_lat_lng = ""
text_for_search = "Restaurants in Tokyo around Akhibara"
#city_data = get_attraction(city, user_lat_lng, text_for_search)

place_name_list, place_geo_loc_list, place_id_list, place_url_list, plat_plng_list, place_photo_url_list = get_attraction(city, user_lat_lng, text_for_search)


print("*^^^^^^^^^^^length of place_name_list is: ", str(len(place_name_list)))






#x_list = zip(place_name_list, place_geo_loc_list, place_id_list, place_url_list, plat_plng_list, place_photo_url_list)
#keys_list = range(1, len(place_name_list))


'''
RESULTS = [
    ['apple','cherry','orange','pineapple','strawberry']
]
with open("output.csv",'wb') as resultFile:
    wr = csv.writer(resultFile, dialect='excel')
    wr.writerows(RESULTS)
'''

'''
import csv
RESULT = ['apple','cherry','orange','pineapple','strawberry']
with open("output.csv",'wb') as resultFile:
    wr = csv.writer(resultFile, dialect='excel')
    wr.writerow(RESULT)

'''

#titles
RESULT = ['Place Name', 'Place Google Map Link', 'Place Photo Link', 'Place Location Coordinates (Lat, Long)']
with open("akhibara.csv",'w') as resultFile:
    wr = csv.writer(resultFile, dialect='excel')
    #wr = csv.writer(sys.stderr, dialect='excel') #csv.writer(f)

    wr.writerow(RESULT)
#

RESULT = []

#import csv
#RESULT = ['apple','cherry','orange','pineapple','strawberry']
#RESULT = place_name_list, place_geo_loc_list, place_id_list, place_url_list, plat_plng_list, place_photo_url_list

for i in range(0,len(place_name_list) - 1):

   RESULT.append(place_name_list[i])
   #RESULT.append(place_geo_loc_list[i])
   #RESULT.append(place_id_list[i])
   RESULT.append(place_url_list[i])
   RESULT.append(place_photo_url_list[i])
   RESULT.append(plat_plng_list[i])



   with open("akhibara.csv",'a') as resultFile:
       wr = csv.writer(resultFile, dialect='excel')
       #wr = csv.writer(sys.stderr, dialect='excel') #csv.writer(f)

       wr.writerow(RESULT)

   RESULT = []



